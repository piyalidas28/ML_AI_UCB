{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODO: add context and problem statement etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import modules and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "import warnings\n",
        "from datetime import datetime, timedelta\n",
        "from time import time\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_squared_log_error, r2_score\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option(\n",
        "    \"display.max_columns\", None\n",
        ")  # displays all columns (wrap-around) in pandas statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "output": {
          "id": 491287236843333,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Orders (Train):\n",
            "Customers (Train):\n",
            "Products (Train):\n",
            "Payments (Train):\n",
            "Order Items (Train):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>seller_id</th>\n",
              "      <th>price</th>\n",
              "      <th>shipping_charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Axfy13Hk4PIk</td>\n",
              "      <td>90K0C1fIyQUf</td>\n",
              "      <td>ZWM05J9LcBSF</td>\n",
              "      <td>223.51</td>\n",
              "      <td>84.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>v6px92oS8cLG</td>\n",
              "      <td>qejhpMGGVcsl</td>\n",
              "      <td>IjlpYfhUbRQs</td>\n",
              "      <td>170.80</td>\n",
              "      <td>23.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ulpf9skrhjfm</td>\n",
              "      <td>qUS5d2pEAyxJ</td>\n",
              "      <td>77p2EYxcM9MD</td>\n",
              "      <td>64.40</td>\n",
              "      <td>17.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bwJVWupf2keN</td>\n",
              "      <td>639iGvMyv0De</td>\n",
              "      <td>jWzS0ayv9TGf</td>\n",
              "      <td>264.50</td>\n",
              "      <td>30.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dd0QnrMk9Cj5</td>\n",
              "      <td>1lycYGcsic2F</td>\n",
              "      <td>l1pYW6GBnPMr</td>\n",
              "      <td>779.90</td>\n",
              "      <td>30.66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       order_id    product_id     seller_id   price  shipping_charges\n",
              "0  Axfy13Hk4PIk  90K0C1fIyQUf  ZWM05J9LcBSF  223.51             84.65\n",
              "1  v6px92oS8cLG  qejhpMGGVcsl  IjlpYfhUbRQs  170.80             23.79\n",
              "2  Ulpf9skrhjfm  qUS5d2pEAyxJ  77p2EYxcM9MD   64.40             17.38\n",
              "3  bwJVWupf2keN  639iGvMyv0De  jWzS0ayv9TGf  264.50             30.72\n",
              "4  Dd0QnrMk9Cj5  1lycYGcsic2F  l1pYW6GBnPMr  779.90             30.66"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "file_paths = {\n",
        "    \"orders_train\": \"/data/sandcastle/boxes/configerator/source/parin_course/Ecommerce_Order_Dataset/train/df_Orders.csv\",\n",
        "    \"customers_train\": \"/data/sandcastle/boxes/configerator/source/parin_course/Ecommerce_Order_Dataset/train/df_Customers.csv\",\n",
        "    \"products_train\": \"/data/sandcastle/boxes/configerator/source/parin_course/Ecommerce_Order_Dataset/train/df_Products.csv\",\n",
        "    \"payments_train\": \"/data/sandcastle/boxes/configerator/source/parin_course/Ecommerce_Order_Dataset/train/df_Payments.csv\",\n",
        "    \"order_items_train\": \"/data/sandcastle/boxes/configerator/source/parin_course/Ecommerce_Order_Dataset/train/df_OrderItems.csv\",\n",
        "    \"orders_test\": \"/data/sandcastle/boxes/configerator/source/parin_course/Ecommerce_Order_Dataset/test/df_Orders.csv\",\n",
        "    \"customers_test\": \"/data/sandcastle/boxes/configerator/source/parin_course/Ecommerce_Order_Dataset/test/df_Customers.csv\",\n",
        "    \"products_test\": \"/data/sandcastle/boxes/configerator/source/parin_course/Ecommerce_Order_Dataset/test/df_Products.csv\",\n",
        "    \"payments_test\": \"/data/sandcastle/boxes/configerator/source/parin_course/Ecommerce_Order_Dataset/test/df_Payments.csv\",\n",
        "    \"order_items_test\": \"/data/sandcastle/boxes/configerator/source/parin_course/Ecommerce_Order_Dataset/test/df_OrderItems.csv\",\n",
        "}\n",
        "\n",
        "# Load datasets\n",
        "df_orders_train = pd.read_csv(file_paths[\"orders_train\"])\n",
        "df_customers_train = pd.read_csv(file_paths[\"customers_train\"])\n",
        "df_products_train = pd.read_csv(file_paths[\"products_train\"])\n",
        "df_payments_train = pd.read_csv(file_paths[\"payments_train\"])\n",
        "df_order_items_train = pd.read_csv(file_paths[\"order_items_train\"])\n",
        "\n",
        "df_orders_test = pd.read_csv(file_paths[\"orders_test\"])\n",
        "df_customers_test = pd.read_csv(file_paths[\"customers_test\"])\n",
        "df_products_test = pd.read_csv(file_paths[\"products_test\"])\n",
        "df_payments_test = pd.read_csv(file_paths[\"payments_test\"])\n",
        "df_order_items_test = pd.read_csv(file_paths[\"order_items_test\"])\n",
        "\n",
        "# Display the first few rows of each dataframe to understand the structure\n",
        "print(\"Orders (Train):\")\n",
        "display(df_orders_train.head())\n",
        "\n",
        "print(\"Customers (Train):\")\n",
        "display(df_customers_train.head())\n",
        "\n",
        "print(\"Products (Train):\")\n",
        "display(df_products_train.head())\n",
        "\n",
        "print(\"Payments (Train):\")\n",
        "display(df_payments_train.head())\n",
        "\n",
        "print(\"Order Items (Train):\")\n",
        "display(df_order_items_train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train data inspection and data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "output": {
          "id": 1042615537365860,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Orders (Train):\n",
            "Null values:\n",
            "order_id                            0\n",
            "customer_id                         0\n",
            "order_status                        0\n",
            "order_purchase_timestamp            0\n",
            "order_approved_at                   9\n",
            "order_delivered_timestamp        1889\n",
            "order_estimated_delivery_date       0\n",
            "dtype: int64\n",
            "Duplicate values:\n",
            "0\n",
            "\n",
            "Customers (Train):\n",
            "Null values:\n",
            "customer_id                 0\n",
            "customer_zip_code_prefix    0\n",
            "customer_city               0\n",
            "customer_state              0\n",
            "dtype: int64\n",
            "Duplicate values:\n",
            "0\n",
            "\n",
            "Products (Train):\n",
            "Null values:\n",
            "product_id                 0\n",
            "product_category_name    308\n",
            "product_weight_g          15\n",
            "product_length_cm         15\n",
            "product_height_cm         15\n",
            "product_width_cm          15\n",
            "dtype: int64\n",
            "Duplicate values:\n",
            "61865\n",
            "\n",
            "Payments (Train):\n",
            "Null values:\n",
            "order_id                0\n",
            "payment_sequential      0\n",
            "payment_type            0\n",
            "payment_installments    0\n",
            "payment_value           0\n",
            "dtype: int64\n",
            "Duplicate values:\n",
            "0\n",
            "\n",
            "Order Items (Train):\n",
            "Null values:\n",
            "order_id            0\n",
            "product_id          0\n",
            "seller_id           0\n",
            "price               0\n",
            "shipping_charges    0\n",
            "dtype: int64\n",
            "Duplicate values:\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# null values\n",
        "def print_null_duplicates(df):\n",
        "    print(\"Null values:\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"Duplicate values:\")\n",
        "    print(df.duplicated().sum())\n",
        "\n",
        "\n",
        "print(\"\\nOrders (Train):\")\n",
        "print_null_duplicates(df_orders_train)\n",
        "\n",
        "print(\"\\nCustomers (Train):\")\n",
        "print_null_duplicates(df_customers_train)\n",
        "\n",
        "print(\"\\nProducts (Train):\")\n",
        "print_null_duplicates(df_products_train)\n",
        "\n",
        "print(\"\\nPayments (Train):\")\n",
        "print_null_duplicates(df_payments_train)\n",
        "\n",
        "print(\"\\nOrder Items (Train):\")\n",
        "print_null_duplicates(df_order_items_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Orders dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "output": {
          "id": 855544016503885,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 89316 entries, 0 to 89315\n",
            "Data columns (total 7 columns):\n",
            " #   Column                         Non-Null Count  Dtype \n",
            "---  ------                         --------------  ----- \n",
            " 0   order_id                       89316 non-null  object\n",
            " 1   customer_id                    89316 non-null  object\n",
            " 2   order_status                   89316 non-null  object\n",
            " 3   order_purchase_timestamp       89316 non-null  object\n",
            " 4   order_approved_at              89307 non-null  object\n",
            " 5   order_delivered_timestamp      87427 non-null  object\n",
            " 6   order_estimated_delivery_date  89316 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 4.8+ MB\n",
            "False    89316\n",
            "Name: count, dtype: int64\n",
            "False    89316\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_orders_train.info()\n",
        "print(df_orders_train.duplicated(subset=[\"order_id\"]).value_counts())\n",
        "print(df_orders_train.duplicated(subset=[\"customer_id\"]).value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insights:\n",
        "* This can be merged with customers dateset\n",
        "* Following columns are unnecessary\n",
        "  * order_purchase_timestamp\n",
        "  * order_approved_at\n",
        "  * order_delivered_timestamp\n",
        "  * order_estimated_delivery_date\n",
        "* After merge the ID columns can be dropped from the training datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Customers dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "output": {
          "id": 727117806208777,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 89316 entries, 0 to 89315\n",
            "Data columns (total 4 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   customer_id               89316 non-null  object\n",
            " 1   customer_zip_code_prefix  89316 non-null  int64 \n",
            " 2   customer_city             89316 non-null  object\n",
            " 3   customer_state            89316 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 2.7+ MB\n",
            "False    89316\n",
            "Name: count, dtype: int64\n",
            "3735\n",
            "27\n",
            "62812    11454\n",
            "67184    68682\n",
            "21107    72880\n",
            "81274    21870\n",
            "1382     18108\n",
            "44837    37264\n",
            "30569    62030\n",
            "50110    12403\n",
            "9828     44180\n",
            "35581     7980\n",
            "Name: customer_zip_code_prefix, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_customers_train.info()\n",
        "print(df_customers_train.duplicated(subset=[\"customer_id\"]).value_counts())\n",
        "print(df_customers_train[\"customer_city\"].unique().size)\n",
        "print(df_customers_train[\"customer_state\"].unique().size)\n",
        "print(df_customers_train[\"customer_zip_code_prefix\"].sample(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insights\n",
        "* customer_zip_code_prefix is unnecessary and can be dropped\n",
        "* This can be merged with orders dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Products dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "output": {
          "id": 1480504793350147,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 89316 entries, 0 to 89315\n",
            "Data columns (total 6 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   product_id             89316 non-null  object \n",
            " 1   product_category_name  89008 non-null  object \n",
            " 2   product_weight_g       89301 non-null  float64\n",
            " 3   product_length_cm      89301 non-null  float64\n",
            " 4   product_height_cm      89301 non-null  float64\n",
            " 5   product_width_cm       89301 non-null  float64\n",
            "dtypes: float64(4), object(2)\n",
            "memory usage: 4.1+ MB\n",
            "None\n",
            "Null values:\n",
            "product_id                 0\n",
            "product_category_name    308\n",
            "product_weight_g          15\n",
            "product_length_cm         15\n",
            "product_height_cm         15\n",
            "product_width_cm          15\n",
            "dtype: int64\n",
            "Duplicate values:\n",
            "61865\n",
            "71\n",
            "['toys' 'watches_gifts' 'costruction_tools_garden' 'bed_bath_table' 'auto'\n",
            " 'health_beauty' 'cool_stuff' 'garden_tools' 'furniture_decor'\n",
            " 'fashion_shoes' 'sports_leisure' 'baby' 'housewares'\n",
            " 'construction_tools_construction' 'electronics' 'home_appliances' 'audio'\n",
            " 'consoles_games' 'stationery' 'furniture_living_room'\n",
            " 'computers_accessories' 'perfumery'\n",
            " 'kitchen_dining_laundry_garden_furniture' 'fashion_bags_accessories'\n",
            " 'market_place' 'telephony' 'home_construction' nan 'office_furniture'\n",
            " 'industry_commerce_and_business' 'food_drink' 'drinks'\n",
            " 'agro_industry_and_commerce' 'signaling_and_security' 'food' 'pet_shop'\n",
            " 'luggage_accessories' 'home_appliances_2' 'small_appliances'\n",
            " 'tablets_printing_image' 'construction_tools_lights'\n",
            " 'musical_instruments' 'home_confort' 'air_conditioning'\n",
            " 'construction_tools_safety' 'costruction_tools_tools' 'books_technical'\n",
            " 'books_general_interest' 'books_imported' 'computers' 'cine_photo'\n",
            " 'music' 'fashion_male_clothing' 'fashion_sport' 'fixed_telephony'\n",
            " 'fashion_underwear_beach' 'furniture_bedroom' 'art' 'christmas_supplies'\n",
            " 'dvds_blu_ray' 'flowers' 'la_cuisine' 'furniture_mattress_and_upholstery'\n",
            " 'small_appliances_home_oven_and_coffee' 'home_comfort_2'\n",
            " 'arts_and_craftmanship' 'party_supplies' 'fashion_childrens_clothes'\n",
            " 'fashio_female_clothing' 'security_and_services' 'diapers_and_hygiene']\n"
          ]
        }
      ],
      "source": [
        "print(df_products_train.info())\n",
        "# removing duplicates from products dataset\n",
        "# df_products_train = df_products_train.drop_duplicates()\n",
        "print_null_duplicates(df_products_train)\n",
        "print(df_products_train[\"product_category_name\"].unique().size)\n",
        "print(df_products_train[\"product_category_name\"].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insights:\n",
        "* We can remove the duplicate rows from the dataset\n",
        "* Marginal number of rows have product_category_name as nan\n",
        "  * We would still keep them in case some of those products are very popular"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Order items dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "output": {
          "id": 2188086354890518,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 89316 entries, 0 to 89315\n",
            "Data columns (total 5 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   order_id          89316 non-null  object \n",
            " 1   product_id        89316 non-null  object \n",
            " 2   seller_id         89316 non-null  object \n",
            " 3   price             89316 non-null  float64\n",
            " 4   shipping_charges  89316 non-null  float64\n",
            "dtypes: float64(2), object(3)\n",
            "memory usage: 3.4+ MB\n",
            "None\n",
            "False    89316\n",
            "Name: count, dtype: int64\n",
            "True     61865\n",
            "False    27451\n",
            "Name: count, dtype: int64\n",
            "True     86387\n",
            "False     2929\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df_order_items_train.info())\n",
        "print(df_order_items_train.duplicated(subset=[\"order_id\"]).value_counts())\n",
        "print(df_order_items_train.duplicated(subset=[\"product_id\"]).value_counts())\n",
        "print(df_order_items_train.duplicated(subset=[\"seller_id\"]).value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_order_items_train[\"price\"].hist(column=\"price\", bins=500, figsize=(15, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_order_items_train[\"shipping_charges\"].hist(\n",
        "#     column=\"shipping_charges\", bins=500, figsize=(15, 8)\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insights:\n",
        "* Seller id is unnecessary\n",
        "* This dataset can be merged with orders dataset\n",
        "* Once merged, the id columns can be dropped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Payments dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "output": {
          "id": 1049296396091701,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 89316 entries, 0 to 89315\n",
            "Data columns (total 5 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   order_id              89316 non-null  object \n",
            " 1   payment_sequential    89316 non-null  int64  \n",
            " 2   payment_type          89316 non-null  object \n",
            " 3   payment_installments  89316 non-null  int64  \n",
            " 4   payment_value         89316 non-null  float64\n",
            "dtypes: float64(1), int64(2), object(2)\n",
            "memory usage: 3.4+ MB\n",
            "None\n",
            "False    89316\n",
            "Name: count, dtype: int64\n",
            "['credit_card' 'wallet' 'voucher' 'debit_card']\n",
            "[ 1  8  2  6  3  4  9  5 23 11 18 10  7 12 13 26 15 14 17 24 21 20 16 19\n",
            " 22 29 25 28]\n",
            "[ 1  8  4  2  5  6 10  3  7  9 18 12 24 15 11 13 21 16 20 14 17 23 22  0]\n"
          ]
        }
      ],
      "source": [
        "print(df_payments_train.info())\n",
        "print(df_payments_train.duplicated(subset=[\"order_id\"]).value_counts())\n",
        "print(df_payments_train[\"payment_type\"].unique())\n",
        "print(df_payments_train[\"payment_sequential\"].unique())\n",
        "print(df_payments_train[\"payment_installments\"].unique())\n",
        "\n",
        "# df_payments_train[\"payment_value\"].hist(\n",
        "#     column=\"payment_value\", bins=500, figsize=(15, 8)\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insights:\n",
        "* Since all orders are unique, this can be merged with the orders table as well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Clean datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "output": {
          "id": 804250464909211,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "def clean_orders_dataset(df):\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    df.drop(\n",
        "        columns=[\n",
        "            \"order_purchase_timestamp\",\n",
        "            \"order_approved_at\",\n",
        "            \"order_delivered_timestamp\",\n",
        "            \"order_estimated_delivery_date\",\n",
        "        ],\n",
        "        inplace=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def clean_customers_dataset(df):\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    df.drop(columns=[\"customer_zip_code_prefix\"], inplace=True)\n",
        "\n",
        "\n",
        "def clean_products_dataset(df):\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "\n",
        "def clean_order_items_dataset(df):\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    df.drop(columns=[\"seller_id\"], inplace=True)\n",
        "\n",
        "\n",
        "def clean_payments_dataset(df):\n",
        "    df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [],
      "source": [
        "# clean train datasets\n",
        "clean_orders_dataset(df_orders_train)\n",
        "clean_customers_dataset(df_customers_train)\n",
        "clean_products_dataset(df_products_train)\n",
        "clean_order_items_dataset(df_order_items_train)\n",
        "clean_payments_dataset(df_payments_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merge datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "output": {
          "id": 528482296437771,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 89316 entries, 0 to 89315\n",
            "Data columns (total 17 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   order_id               89316 non-null  object \n",
            " 1   customer_id            89316 non-null  object \n",
            " 2   order_status           89316 non-null  object \n",
            " 3   product_id             89316 non-null  object \n",
            " 4   price                  89316 non-null  float64\n",
            " 5   shipping_charges       89316 non-null  float64\n",
            " 6   customer_city          89316 non-null  object \n",
            " 7   customer_state         89316 non-null  object \n",
            " 8   product_category_name  89008 non-null  object \n",
            " 9   product_weight_g       89301 non-null  float64\n",
            " 10  product_length_cm      89301 non-null  float64\n",
            " 11  product_height_cm      89301 non-null  float64\n",
            " 12  product_width_cm       89301 non-null  float64\n",
            " 13  payment_sequential     89316 non-null  int64  \n",
            " 14  payment_type           89316 non-null  object \n",
            " 15  payment_installments   89316 non-null  int64  \n",
            " 16  payment_value          89316 non-null  float64\n",
            "dtypes: float64(7), int64(2), object(8)\n",
            "memory usage: 11.6+ MB\n",
            "Null values:\n",
            "order_id                   0\n",
            "customer_id                0\n",
            "order_status               0\n",
            "product_id                 0\n",
            "price                      0\n",
            "shipping_charges           0\n",
            "customer_city              0\n",
            "customer_state             0\n",
            "product_category_name    308\n",
            "product_weight_g          15\n",
            "product_length_cm         15\n",
            "product_height_cm         15\n",
            "product_width_cm          15\n",
            "payment_sequential         0\n",
            "payment_type               0\n",
            "payment_installments       0\n",
            "payment_value              0\n",
            "dtype: int64\n",
            "Duplicate values:\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "def merge_datasets(df_orders, df_order_items, df_customers, df_products, df_payments):\n",
        "    return (\n",
        "        df_orders.merge(df_order_items, on=\"order_id\", how=\"outer\")\n",
        "        .merge(df_customers, on=\"customer_id\", how=\"outer\")\n",
        "        .merge(df_products, on=\"product_id\", how=\"outer\")\n",
        "        .merge(df_payments, on=\"order_id\", how=\"outer\")\n",
        "    )\n",
        "\n",
        "\n",
        "df = merge_datasets(\n",
        "    df_orders_train,\n",
        "    df_order_items_train,\n",
        "    df_customers_train,\n",
        "    df_products_train,\n",
        "    df_payments_train,\n",
        ")\n",
        "df.info()\n",
        "print_null_duplicates(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop(columns=[\"order_id\", \"customer_id\", \"product_id\"], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploratory data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "bento_kernel_default"
    }
  }
}
